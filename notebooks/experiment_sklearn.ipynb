{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.src.pandas_transform.pandas_col_transform import PandasColumnTransformer\n",
    "from app.src.pandas_transform.impute_by_group import ImputeNumericalByGroup, ImputeCategoricalByGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n",
      "Doctest mode is: ON\n"
     ]
    }
   ],
   "source": [
    "%doctest_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introductory example from here: [https://scikit-learn.org/stable/getting_started.html](https://scikit-learn.org/stable/getting_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "X = [[ 1,  2,  3],  # 2 samples, 3 features\n",
    "     [11, 12, 13]]\n",
    "y = [0, 1]  # classes of each sample\n",
    "clf.fit(X, y)\n",
    "RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method generally accepts 2 inputs:\n",
    "- The samples matrix (or design matrix) `X`. The size of `X` is typically (`n_samples`, `n_features`), which means that samples are represented as rows and features are represented as columns.\n",
    "- The target values `y` which are real numbers for regression tasks, or integers for classification (or any other discrete set of values). `y` is usually 1d array where the `i`th entry corresponds to the target of the `i`th sample (row) of `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [11, 12, 13]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)  # predict classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = [[0, 15], [1, -10]]\n",
    "\n",
    "# scale data according to computed scaling values\n",
    "StandardScaler().fit(X1).transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split it into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Don't seem to need the following - legacy?\n",
    "# Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#                 ('logisticregression', LogisticRegression())])\n",
    "\n",
    "# we can now use it like any other estimator\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_url = \"https://raw.githubusercontent.com/Mjboothaus/titanic/main/data\"\n",
    "    titanic_training = pd.read_csv(f\"{data_url}/train.csv\")\n",
    "    titanic_test= pd.read_csv(f\"{data_url}/test.csv\")\n",
    "    return titanic_training, titanic_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_training, titanic_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_fields = [\"PassengerId\", \"Name\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "# Should also drop \"Embarked\" as it should have nothing to do with passenger survival or otherwise\n",
    "# Probably also \"Cabin\" -- assume there is a relationship with \"Pclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_training.drop(drop_fields, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0      1      0\n",
       "1         1       1  female  38.0      1      0\n",
       "2         1       3  female  26.0      0      0\n",
       "3         1       1  female  35.0      1      0\n",
       "4         0       3    male  35.0      0      0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_training[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titanic_training[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Sex         0\n",
       "Age       177\n",
       "SibSp       0\n",
       "Parch       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Last step of Pipeline should implement fit or be the string 'passthrough'. '[ImputeNumericalByGroup(target_col='Age', copy=True, groupby_col=['Pclass'], key_error_on_unseen=True, imputation_values=None, return_df=True), OneHotEncoder()]' (type <class 'list'>) doesn't",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  Input \u001b[1;32mIn [94]\u001b[0m in \u001b[1;35m<cell line: 1>\u001b[0m\n    pipe = make_pipeline([\n",
      "  File \u001b[1;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/pipeline.py:378\u001b[0m in \u001b[1;35mfit\u001b[0m\n    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \u001b[1;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/pipeline.py:316\u001b[0m in \u001b[1;35m_fit\u001b[0m\n    self._validate_steps()\n",
      "\u001b[0;36m  File \u001b[0;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/pipeline.py:220\u001b[0;36m in \u001b[0;35m_validate_steps\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise TypeError(\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m\u001b[0;31m:\u001b[0m Last step of Pipeline should implement fit or be the string 'passthrough'. '[ImputeNumericalByGroup(target_col='Age', copy=True, groupby_col=['Pclass'], key_error_on_unseen=True, imputation_values=None, return_df=True), OneHotEncoder()]' (type <class 'list'>) doesn't\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline([\n",
    "    ImputeNumericalByGroup(target_col=\"Age\", groupby_col=[\"Pclass\"], return_df=True),\n",
    "    OneHotEncoder()]).fit(X)  #,\n",
    "    # LogisticRegression(random_state=0, max_iter=1000)).fit(X, y)\n",
    "\n",
    "    #, ImputeCategoricalByGroup(target_col=\"Embarked\", groupby_col=[\"Pclass\"], return_df=True, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'sklearn.pipeline.Pipeline'>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch\n",
       "0       3    0  22.0      1      0\n",
       "1       1    0  38.0      1      0\n",
       "2       3    0  26.0      0      0\n",
       "3       1    0  35.0      1      0\n",
       "4       3    0  35.0      0      0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[\"Sex\"] = X[\"Sex\"].apply(lambda x: 1 if x == \"male\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  Input \u001b[1;32mIn [63]\u001b[0m in \u001b[1;35m<cell line: 1>\u001b[0m\n    clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y)\n",
      "  File \u001b[1;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1138\u001b[0m in \u001b[1;35mfit\u001b[0m\n    X, y = self._validate_data(\n",
      "  File \u001b[1;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/base.py:596\u001b[0m in \u001b[1;35m_validate_data\u001b[0m\n    X, y = check_X_y(X, y, **check_params)\n",
      "  File \u001b[1;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/utils/validation.py:1074\u001b[0m in \u001b[1;35mcheck_X_y\u001b[0m\n    X = check_array(\n",
      "  File \u001b[1;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/utils/validation.py:899\u001b[0m in \u001b[1;35mcheck_array\u001b[0m\n    _assert_all_finite(\n",
      "\u001b[0;36m  File \u001b[0;32m~/code/github/mjboothaus/titanic/.venv_dev_titanic-streamlit-app/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001b[0;36m in \u001b[0;35m_assert_all_finite\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise ValueError(msg_err)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m\u001b[0;31m:\u001b[0m Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y)\n",
    "clf.predict(X)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv_dev_titanic-streamlit-app': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3de96be564863eb70bacda9d696b254a7026b525f8ce08839ccf359adbdf151e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
